---
title: "DATA643_Project5_Spark"
author: "Yun Mai"
date: "July 8, 2017"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r,eval=F}
install.packages("sparklyr",repos = "http://cran.us.r-project.org")
packageVersion("sparklyr")
```

```{r}
require(sparklyr)

# tried to install the version 2.1.0
# sparklyr::spark_install(version = "2.1.0")
# But got a error message:
# Error in spark_install_find(version, hadoop_version, installedOnly = FALSE,  : Spark version not available.

# checke the spark version available for installation from sparklyr 
# spark_available_versions()
# Error in file(file, "rt") : cannot open the connection

# there is no 2.1.0 so chose spark 2.0.2, hadoop: 2.7
spark_install(version = "2.0.2", hadoop_version = 2.7, reset = TRUE, logging = "INFO", verbose = interactive())

# Installing Spark 2.0.2 for Hadoop 2.7 or later.
# Downloading from:- 'https://d3kbcqa49mib13.cloudfront.net/spark-2.0.2-bin-hadoop2.7.tgz'
# Installing to:- 'C:\Users\lzq\AppData\Local\rstudio\spark\Cache/spark-2.0.2-bin-hadoop2.7'
# trying URL 'https://d3kbcqa49mib13.cloudfront.net/spark-2.0.2-bin-hadoop2.7.tgz'
# Content type 'application/x-tar' length 187426587 bytes (178.7 MB)
# downloaded 178.7 MB

spark_installed_versions()
# so in addition to Spark 2.0.2, there are 2.1.0 which installed before under the directory "C:\Users\lzq\AppData\Local\rstudio\spark\Cache"

# devtools::install_github("rstudio/sparklyr") 
# if install sparklyr from rstudio github, we will get newer version of sparklyr and Spark (such as 2.1.0) 
```

```{r}
# check the current SPARK_HOME
Sys.getenv("SPARK_HOME")

#check config
spark_config()
```
```{r}
#change SPARK_HOME
Sys.setenv(SPARK_HOME="C:/Users/lzq/AppData/Local/rstudio/spark/Cache/spark-2.0.2-bin-hadoop2.7")

# connect to spark
sc <- spark_connect(master = "local",version ="2.0.2")

# succeed ! Got the following message
# Created default hadoop bin directory under: C:\Users\lzq\AppData\Local\rstudio\spark\Cache\spark-2.0.2-bin-hadoop2.7\tmp\hadoop
```

```{r}
# verify the spark home directory
spark_home_dir()
```

To verify the connection
```{r}
#iris_tbl <- copy_to(sc, iris)
#iris_tbl

```

I put a lot of efforts to make sparklyr work in Windows 10 but failed to wirte data into spark. I posted the issue in RStudion/sparklyr for help but did not get response yet. So I could not finish project 5 in time. I will try SparkR. Hopefully I can figure out how to use Spark in R and apply it in the final project.
